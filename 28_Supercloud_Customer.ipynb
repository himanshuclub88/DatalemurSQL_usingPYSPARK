{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfc80504",
   "metadata": {},
   "source": [
    "# Supercloud Customer  \n",
    "**Microsoft SQL Interview Question**\n",
    "\n",
    "---\n",
    "\n",
    "### Question  \n",
    "A Microsoft Azure Supercloud customer is defined as a customer who has purchased at least one product from every product category listed in the products table.  \n",
    "\n",
    "Write a query that identifies the customer IDs of these Supercloud customers.\n",
    "\n",
    "---\n",
    "\n",
    "### Tables  \n",
    "\n",
    "#### `customer_contracts` Table:\n",
    "| Column Name    | Type    |\n",
    "|----------------|---------|\n",
    "| customer_id    | integer |\n",
    "| product_id     | integer |\n",
    "| amount         | integer |\n",
    "\n",
    "**Example Input:**\n",
    "| customer_id | product_id | amount |\n",
    "|-------------|------------|--------|\n",
    "| 1           | 1          | 1000   |\n",
    "| 1           | 3          | 2000   |\n",
    "| 1           | 5          | 1500   |\n",
    "| 2           | 2          | 3000   |\n",
    "| 2           | 6          | 2000   |\n",
    "\n",
    "---\n",
    "\n",
    "#### `products` Table:\n",
    "| Column Name      | Type    |\n",
    "|------------------|---------|\n",
    "| product_id       | integer |\n",
    "| product_category | string  |\n",
    "| product_name     | string  |\n",
    "\n",
    "**Example Input:**\n",
    "| product_id | product_category | product_name              |\n",
    "|------------|------------------|---------------------------|\n",
    "| 1          | Analytics        | Azure Databricks          |\n",
    "| 2          | Analytics        | Azure Stream Analytics    |\n",
    "| 4          | Containers       | Azure Kubernetes Service  |\n",
    "| 5          | Containers       | Azure Service Fabric      |\n",
    "| 6          | Compute          | Virtual Machines          |\n",
    "| 7          | Compute          | Azure Functions           |\n",
    "\n",
    "---\n",
    "\n",
    "### Example Output:\n",
    "| customer_id |\n",
    "|-------------|\n",
    "| 1           |\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation:  \n",
    "Customer 1 purchased products from **Analytics**, **Containers**, and **Compute**, covering all categories, hence is a Supercloud customer.  \n",
    "Customer 2 did not purchase from all categories (e.g., missing Containers), so they are excluded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd49af39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------+------+\n",
      "|customer_id|product_id|amount|\n",
      "+-----------+----------+------+\n",
      "|          1|         1|  1000|\n",
      "|          1|         3|  2000|\n",
      "|          1|         5|  1500|\n",
      "|          2|         2|  3000|\n",
      "|          2|         6|  2000|\n",
      "+-----------+----------+------+\n",
      "\n",
      "+----------+----------------+--------------------+\n",
      "|product_id|product_category|        product_name|\n",
      "+----------+----------------+--------------------+\n",
      "|         1|       Analytics|    Azure Databricks|\n",
      "|         2|       Analytics|Azure Stream Anal...|\n",
      "|         3|      Containers|Azure Kubernetes ...|\n",
      "|         4|      Containers|Azure Service Fabric|\n",
      "|         5|         Compute|    Virtual Machines|\n",
      "|         6|         Compute|     Azure Functions|\n",
      "+----------+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.master('local[1]').getOrCreate()\n",
    "\n",
    "# Sample data for customer_contracts\n",
    "customer_contracts_data = [\n",
    "    (1, 1, 1000),\n",
    "    (1, 3, 2000),\n",
    "    (1, 5, 1500),\n",
    "    (2, 2, 3000),\n",
    "    (2, 6, 2000)\n",
    "]\n",
    "\n",
    "customer_contracts_columns = [\"customer_id\", \"product_id\", \"amount\"]\n",
    "\n",
    "customer_contracts_df = spark.createDataFrame(customer_contracts_data, customer_contracts_columns)\n",
    "\n",
    "# Sample data for products\n",
    "products_data = [\n",
    "    (1, \"Analytics\", \"Azure Databricks\"),\n",
    "    (2, \"Analytics\", \"Azure Stream Analytics\"),\n",
    "    (3, \"Containers\", \"Azure Kubernetes Service\"),\n",
    "    (4, \"Containers\", \"Azure Service Fabric\"),\n",
    "    (5, \"Compute\", \"Virtual Machines\"),\n",
    "    (6, \"Compute\", \"Azure Functions\")\n",
    "]\n",
    "\n",
    "products_columns = [\"product_id\", \"product_category\", \"product_name\"]\n",
    "\n",
    "products_df = spark.createDataFrame(products_data, products_columns)\n",
    "\n",
    "# Show DataFrames (optional)\n",
    "customer_contracts_df.show()\n",
    "products_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23981747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|customer_id|\n",
      "+-----------+\n",
      "|          1|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k= products_df.agg(countDistinct('product_category')).collect()[0][0]\n",
    "customer_contracts_df.join(products_df,\n",
    "                           customer_contracts_df.product_id==products_df.product_id)\\\n",
    "                    .groupBy('customer_id').agg(countDistinct('product_category').alias('cnt'))\\\n",
    "                    .where(col('cnt')==k)\\\n",
    "                    .drop('cnt').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce7ba072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|customer_id|\n",
      "+-----------+\n",
      "|          1|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_contracts_df.createOrReplaceTempView('customer_contracts')\n",
    "products_df.createOrReplaceTempView('products')\n",
    "\n",
    "spark.sql(\n",
    "'''\n",
    "SELECT customer_id \n",
    "FROM customer_contracts c JOIN products p\n",
    "on c.product_id=p.product_id\n",
    "GROUP by customer_id\n",
    "HAVING count(DISTINCT product_category) = (SELECT count(DISTINCT product_category) FROM products)\n",
    "''').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
