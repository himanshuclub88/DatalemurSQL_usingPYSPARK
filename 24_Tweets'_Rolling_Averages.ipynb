{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c22df9c",
   "metadata": {},
   "source": [
    "# Tweets' Rolling Averages  \n",
    "**Twitter SQL Interview Question**  \n",
    "\n",
    "---\n",
    "\n",
    "### Question  \n",
    "This is the same question as problem #10 in the SQL Chapter of *Ace the Data Science Interview*!  \n",
    "\n",
    "Given a table of tweet data over a specified time period, calculate the 3-day rolling average of tweets for each user. Output the user ID, tweet date, and rolling averages rounded to 2 decimal places.  \n",
    "\n",
    "---\n",
    "\n",
    "### Notes  \n",
    "- A rolling average, also known as a moving average or running mean, is a time-series technique that examines trends in data over a specified period of time.  \n",
    "- In this case, we want to determine how the tweet count for each user changes over a 3-day period.  \n",
    "- Effective April 7th, 2023, the problem statement, solution and hints for this question have been revised.  \n",
    "\n",
    "---\n",
    "\n",
    "### `tweets` Table:\n",
    "\n",
    "| Column Name  | Type      |\n",
    "|--------------|-----------|\n",
    "| user_id      | integer   |\n",
    "| tweet_date   | timestamp |\n",
    "| tweet_count  | integer   |\n",
    "\n",
    "---\n",
    "\n",
    "### Example Input:\n",
    "\n",
    "| user_id | tweet_date          | tweet_count |\n",
    "|---------|---------------------|-------------|\n",
    "| 111     | 06/01/2022 00:00:00 | 2           |\n",
    "| 111     | 06/02/2022 00:00:00 | 1           |\n",
    "| 111     | 06/03/2022 00:00:00 | 3           |\n",
    "| 111     | 06/04/2022 00:00:00 | 4           |\n",
    "| 111     | 06/05/2022 00:00:00 | 5           |\n",
    "\n",
    "---\n",
    "\n",
    "### Example Output:\n",
    "\n",
    "| user_id | tweet_date          | rolling_avg_3d |\n",
    "|---------|---------------------|----------------|\n",
    "| 111     | 06/01/2022 00:00:00 | 2.00           |\n",
    "| 111     | 06/02/2022 00:00:00 | 1.50           |\n",
    "| 111     | 06/03/2022 00:00:00 | 2.00           |\n",
    "| 111     | 06/04/2022 00:00:00 | 2.67           |\n",
    "| 111     | 06/05/2022 00:00:00 | 4.00           |\n",
    "\n",
    "---\n",
    "\n",
    "### Explanation  \n",
    "For each user and date, the rolling average is calculated based on the current date and the two previous dates (i.e., a 3-day window). For instance, on 06/03/2022, the average is calculated as:  \n",
    "(2 + 1 + 3) / 3 = 2.00  \n",
    "\n",
    "As we proceed through time, this average updates to reflect only the most recent three days of tweet activity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "138795f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------+\n",
      "|user_id|tweet_date         |tweet_count|\n",
      "+-------+-------------------+-----------+\n",
      "|111    |2022-06-01 00:00:00|2          |\n",
      "|111    |2022-06-02 00:00:00|1          |\n",
      "|111    |2022-06-03 00:00:00|3          |\n",
      "|111    |2022-06-04 00:00:00|4          |\n",
      "|111    |2022-06-05 00:00:00|5          |\n",
      "+-------+-------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, TimestampType\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.master('local[1]').appName(\"TweetsRollingAverages\").getOrCreate()\n",
    "\n",
    "# Define schema\n",
    "schema = StructType([\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"tweet_date\", TimestampType(), True),\n",
    "    StructField(\"tweet_count\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Create data\n",
    "data = [\n",
    "    (111, datetime.strptime(\"06/01/2022 00:00:00\", \"%m/%d/%Y %H:%M:%S\"), 2),\n",
    "    (111, datetime.strptime(\"06/02/2022 00:00:00\", \"%m/%d/%Y %H:%M:%S\"), 1),\n",
    "    (111, datetime.strptime(\"06/03/2022 00:00:00\", \"%m/%d/%Y %H:%M:%S\"), 3),\n",
    "    (111, datetime.strptime(\"06/04/2022 00:00:00\", \"%m/%d/%Y %H:%M:%S\"), 4),\n",
    "    (111, datetime.strptime(\"06/05/2022 00:00:00\", \"%m/%d/%Y %H:%M:%S\"), 5)\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "tweets_df = spark.createDataFrame(data, schema)\n",
    "\n",
    "# Show DataFrame\n",
    "tweets_df.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd7c1b4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------+\n",
      "|user_id|         tweet_date|rolling_avg_3d|\n",
      "+-------+-------------------+--------------+\n",
      "|    111|2022-06-01 00:00:00|           2.0|\n",
      "|    111|2022-06-02 00:00:00|           1.5|\n",
      "|    111|2022-06-03 00:00:00|           2.0|\n",
      "|    111|2022-06-04 00:00:00|          2.67|\n",
      "|    111|2022-06-05 00:00:00|           4.0|\n",
      "+-------+-------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "winspec= Window.partitionBy('user_id').orderBy('tweet_date').rowsBetween(-2,0)\n",
    "tweets_df.withColumn('rolling_avg_3d', round(avg('tweet_count').over(winspec),2))\\\n",
    "    .drop('tweet_count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2158051e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+--------------+\n",
      "|user_id|         tweet_date|rolling_avg_3d|\n",
      "+-------+-------------------+--------------+\n",
      "|    111|2022-06-01 00:00:00|           2.0|\n",
      "|    111|2022-06-02 00:00:00|           1.5|\n",
      "|    111|2022-06-03 00:00:00|           2.0|\n",
      "|    111|2022-06-04 00:00:00|          2.67|\n",
      "|    111|2022-06-05 00:00:00|           4.0|\n",
      "+-------+-------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tweets_df.createOrReplaceTempView('tweets')\n",
    "spark.sql('''SELECT user_id,tweet_date,\n",
    "round(avg(tweet_count) \n",
    "over(PARTITION BY user_id ORDER BY tweet_date RANGE BETWEEN INTERVAL '2 day' PRECEDING and CURRENT ROW ),2) as rolling_avg_3d\n",
    "FROM tweets;''').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
